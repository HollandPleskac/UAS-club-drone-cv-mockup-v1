{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b84fb5e0",
   "metadata": {},
   "source": [
    "# Drop Zone Detection\n",
    "\n",
    "**About the notebook**\n",
    "This notebook is meant as a mockup of using the ultralytics/yolov5 model for drone object detection. The aim is to position the \"drop zone\" in the center of the screen directly below the camera. The program gives directions on how to get to the center of the screen. The thought of this is that you could steer the drone to the desired spot then drop the payload."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae31fa4",
   "metadata": {},
   "source": [
    "# Step 1: Get Data\n",
    "\n",
    "1. take pictures with camera\n",
    "2. use labelImg to label all images\n",
    "3. create images and labels folder in /data\n",
    "4. create yaml file in /yolov5 for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "974e790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create images folder from zip file\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\"data_v2/images\"):\n",
    "    import zipfile as zf\n",
    "    files = zf.ZipFile(\"drop_zone_dataset_1.zip\")\n",
    "    files.extractall(\"data_v2\")\n",
    "    files.close()\n",
    "\n",
    "# for some reason this extracts as Drop zone images.  rename to data/Drop zone images to data/images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fde982",
   "metadata": {},
   "source": [
    "# Step 2: Train the model\n",
    "**Errors I got while training**\n",
    "\n",
    "* got error saying to clear cache file in /data -> solved by clearing cache file\n",
    "* got error saying class name 15 doesn't match to 0. When labelImg exports, it exports like 15 additional classes.\n",
    "    * https://github.com/heartexlabs/labelImg/issues/624\n",
    "    * Solution is to go into cloned labelImg repo and remove everything in predefined_classes.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17e3a994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd yolov5 && python train.py --img 640 --batch 16 --epochs 100 --data custom_dataset_v2.yaml --weights yolov5s.pt --workers 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9f7a42",
   "metadata": {},
   "source": [
    "**Things I noticed while training**\n",
    "\n",
    "* increasing --img will increase the time per epoch\n",
    "* increasing --img from 300 to 640 allowed the model to detect big images (moving the camera close to the drop zone)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cfda50",
   "metadata": {},
   "source": [
    "# Step 3: Get Model instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc53807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', \"./yolov5/runs/train/exp8/weights/best.pt\")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8f0ee3",
   "metadata": {},
   "source": [
    "# Step 4: Use Open CV to evaluate the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82895b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Get All Image Paths\n",
    "all_img_paths = glob.glob(\"data_v2/images/*.jpg\")\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "for i in range(1):\n",
    "    # Pick Random Path\n",
    "    random_path = random.choice(all_img_paths)\n",
    "#     random_path = \"data_v2/multiple-zones-test-img.jpg\" # This image proves results_xyxy sorted with highest confidence first (confidence descending)\n",
    "    plt.subplot(2,4,i+1) # setup subplot\n",
    "    img = cv2.imread(random_path)\n",
    "    \n",
    "    # Get Results from Model\n",
    "    results = model(img)\n",
    "    print(\"results.shape\",img.shape)\n",
    "    \n",
    "    # Show Image\n",
    "    show_img = cv2.cvtColor(np.squeeze(results.render()), cv2.COLOR_BGR2RGB)\n",
    "#     show_img = np.squeeze(results.render())\n",
    "    \n",
    "    # Screen dimensions\n",
    "    height=img.shape[0]\n",
    "    width=img.shape[1]\n",
    "    \n",
    "    # Screen Center\n",
    "    screen_center_x = width /2\n",
    "    screen_center_y = height /2\n",
    "    screen_center_x, screen_center_y = int(screen_center_x), int(screen_center_y)\n",
    "    print(\"center_x\", screen_center_x, \"center_y\", screen_center_y)\n",
    "    \n",
    "    if not results.pandas().xyxy[0].empty:\n",
    "        # Sort Results\n",
    "        results_xyxy = results.pandas().xyxy[0].sort_values(by=[\"confidence\"], ascending=False) # row 0 has highest confidence\n",
    "        print(\"results.xyxy sorted:\\n\", results_xyxy)\n",
    "        print(\"highest confidence\", results.pandas().xyxy[0][\"confidence\"].max())\n",
    "        print(\"row with highest result:\", results_xyxy[\"confidence\"].idxmax())\n",
    "        highest_confidence_row = results_xyxy.iloc[0]\n",
    "    \n",
    "        # Bounding Box Data\n",
    "        xmin = int(highest_confidence_row[\"xmin\"])\n",
    "        xmax = int(highest_confidence_row[\"xmax\"])\n",
    "        ymin = int(highest_confidence_row[\"ymin\"])\n",
    "        ymax = int(highest_confidence_row[\"ymax\"])\n",
    "        center_x = (xmin + xmax)/2\n",
    "        center_y = (ymin + ymax)/2\n",
    "        center_x, center_y = int(center_x), int(center_y)\n",
    "        \n",
    "        # Variables for Text\n",
    "        text = \"Need to move up\"\n",
    "        coordinates = (100,height-100)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        fontScale = 4\n",
    "        color = (255,0,0)\n",
    "        thickness = 10\n",
    "\n",
    "        if (xmax-xmin) * (ymax-ymin) > 200*200:\n",
    "            show_img = cv2.putText(show_img, text, coordinates, font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "            print(\"need to move up\")\n",
    "        else:\n",
    "            # Display Rectangles\n",
    "            if (xmin < screen_center_x - 100):\n",
    "                cv2.arrowedLine(show_img, (width-150, screen_center_y), (width-50, screen_center_y), (0, 255, 0), 30, tipLength = 0.5)\n",
    "                print(\"move to the right\")\n",
    "            elif (xmax > screen_center_x+100):\n",
    "                cv2.arrowedLine(show_img, (150, screen_center_y), (50, screen_center_y), (0, 255, 0), 30, tipLength = 0.5)\n",
    "                print(\"move to the left\")\n",
    "            else:\n",
    "                cv2.circle(show_img, (center_x, center_y), 15, (0, 255, 0), -1)\n",
    "                print(\"on target\")\n",
    "\n",
    "            if (ymin < screen_center_y - 100):\n",
    "                cv2.arrowedLine(show_img, (screen_center_x, height-150), (screen_center_x, height-50), (0, 255, 0), 30, tipLength = 0.5)\n",
    "                print(\"move down\")\n",
    "            elif (ymax > screen_center_y+100):\n",
    "                cv2.arrowedLine(show_img, (screen_center_x, 150), (screen_center_x, 50), (0, 255, 0), 30, tipLength = 0.5)\n",
    "                print(\"move up\")\n",
    "            else:\n",
    "                cv2.circle(show_img, (center_x, center_y), 15, (0, 255, 0), -1)\n",
    "                print(\"on target\")\n",
    "    \n",
    "    # Display target box rectangle\n",
    "    cv2.rectangle(show_img, (screen_center_x-100, screen_center_y-100), (screen_center_x+100, screen_center_y+100), (0, 255, 0), 3)\n",
    "    \n",
    "    # Display middle of detected object\n",
    "#     cv2.circle(show_img, (center_x, center_y), 30, (255, 0, 0), -1)\n",
    "    \n",
    "\n",
    "    plt.imshow(show_img)\n",
    "    \n",
    "    plt.axis(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e787b0d6",
   "metadata": {},
   "source": [
    "**Note** What do you do if the bounding box is bigger than the target zone. Move the drone up, until the bounding box fits inside of the target.\n",
    "\n",
    "**Note** look into this line\n",
    "\n",
    "\"# cv2.imshow('YOLO',cv2.cvtColor( np.squeeze(results.render()),cv2.COLOR_BGR2RGB))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7aee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "printed_a = False\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if (not printed_a):\n",
    "        print(\"frame shape \", frame.shape, \"frame type \",frame.shape)\n",
    "        printed_a=True\n",
    "    \n",
    "    \n",
    "    # Make detections \n",
    "    results = model(frame)\n",
    "    show_img = np.squeeze(results.render())\n",
    "    \n",
    "    # Screen dimensions\n",
    "    height=frame.shape[0]\n",
    "    width=frame.shape[1]\n",
    "    \n",
    "    # Screen Center\n",
    "    screen_center_x = width /2\n",
    "    screen_center_y = height /2\n",
    "    screen_center_x, screen_center_y = int(screen_center_x), int(screen_center_y)\n",
    "    \n",
    "    if not results.pandas().xyxy[0].empty:\n",
    "        # Work With Row\n",
    "        results_xyxy = results.pandas().xyxy[0].sort_values(by=[\"confidence\"], ascending=False) # row 0 has highest confidence\n",
    "        highest_confidence_row = results_xyxy.iloc[0]\n",
    "    \n",
    "        # Bounding Box Data\n",
    "        xmin = int(highest_confidence_row[\"xmin\"])\n",
    "        xmax = int(highest_confidence_row[\"xmax\"])\n",
    "        ymin = int(highest_confidence_row[\"ymin\"])\n",
    "        ymax = int(highest_confidence_row[\"ymax\"])\n",
    "        center_x = (xmin + xmax)/2\n",
    "        center_y = (ymin + ymax)/2\n",
    "        center_x, center_y = int(center_x), int(center_y)\n",
    "        \n",
    "        # Variables for Text\n",
    "        text = \"Need to move up\"\n",
    "        coordinates = (100,height-100)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        fontScale = 4\n",
    "        color = (255,0,0)\n",
    "        thickness = 10\n",
    "        \n",
    "        if (xmax-xmin) * (ymax-ymin) > 200*200:\n",
    "            show_img = cv2.putText(show_img, text, coordinates, font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "        else:\n",
    "            # Display Rectangles\n",
    "            if (xmin < screen_center_x - 100):\n",
    "                cv2.arrowedLine(show_img, (150, screen_center_y), (50, screen_center_y), (0, 255, 0), 30, tipLength = 0.5)\n",
    "            elif (xmax > screen_center_x+100):\n",
    "                cv2.arrowedLine(show_img, (width-150, screen_center_y), (width-50, screen_center_y), (0, 255, 0), 30, tipLength = 0.5)\n",
    "            else:\n",
    "                cv2.circle(show_img, (center_x, center_y), 15, (0, 255, 0), -1)\n",
    "\n",
    "            if (ymin < screen_center_y - 100):\n",
    "                cv2.arrowedLine(show_img, (screen_center_x, 150), (screen_center_x, 50), (0, 255, 0), 30, tipLength = 0.5)\n",
    "            elif (ymax > screen_center_y+100):\n",
    "                cv2.arrowedLine(show_img, (screen_center_x, height-150), (screen_center_x, height-50), (0, 255, 0), 30, tipLength = 0.5)\n",
    "            else:\n",
    "                cv2.circle(show_img, (center_x, center_y), 15, (0, 255, 0), -1)\n",
    "    \n",
    "    # Display target box rectangle\n",
    "    cv2.rectangle(show_img, (screen_center_x-100, screen_center_y-100), (screen_center_x+100, screen_center_y+100), (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow('YOLO',show_img)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cbc9b6",
   "metadata": {},
   "source": [
    "**Code Save**: This was changed to display cv2.arrowedLine\n",
    "```\n",
    "# Display Rectangles\n",
    "if (xmin < screen_center_x - 100):\n",
    "    cv2.rectangle(show_img, (width-150, screen_center_y-25), (width-50, screen_center_y+25), (0, 255, 0), -1)\n",
    "    print(\"move to the right\")\n",
    "elif (xmax > screen_center_x+100):\n",
    "    cv2.rectangle(show_img, (50, screen_center_y-25), (150, screen_center_y+25), (0, 255, 0), -1)\n",
    "    print(\"move to the left\")\n",
    "else:\n",
    "    cv2.circle(show_img, (center_x, center_y), 15, (0, 255, 0), -1)\n",
    "    print(\"on target\")\n",
    "\n",
    "if (ymin < screen_center_y - 100):\n",
    "    cv2.rectangle(show_img, (screen_center_x-25, height-150), (screen_center_x+25, height-50), (0, 255, 0), -1)\n",
    "    print(\"move down\")\n",
    "elif (ymax > screen_center_y+100):\n",
    "    cv2.rectangle(show_img, (screen_center_x-25, 50), (screen_center_x+25, 150), (0, 255, 0), -1)\n",
    "    print(\"move up\")\n",
    "else:\n",
    "    cv2.circle(show_img, (center_x, center_y), 15, (0, 255, 0), -1)\n",
    "    print(\"on target\")\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef4b30d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
